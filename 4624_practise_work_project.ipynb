{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM2sEmfL8ON0SGmwJuNp27x",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nimeshayasith/Computer_vision_Assignment/blob/main/4624_practise_work_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hYnbZO24dZA0",
        "outputId": "e2b3ad9d-83b9-4da6-f141-2efe1625d4da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Successfully mounted Google Drive and changed directory to /content/drive/MyDrive/CV_Assessment_01\n",
            "Found 100 images. Running Advanced Double-CLAHE Pipeline...\n",
            "\n",
            "Processed 10/100 images... Current Avg DSC: 0.6993\n",
            "Processed 20/100 images... Current Avg DSC: 0.7055\n",
            "Processed 30/100 images... Current Avg DSC: 0.7094\n",
            "Processed 40/100 images... Current Avg DSC: 0.6983\n",
            "Processed 50/100 images... Current Avg DSC: 0.7009\n",
            "Processed 60/100 images... Current Avg DSC: 0.6910\n",
            "Processed 70/100 images... Current Avg DSC: 0.6917\n",
            "Processed 80/100 images... Current Avg DSC: 0.6937\n",
            "Processed 90/100 images... Current Avg DSC: 0.6880\n",
            "Processed 100/100 images... Current Avg DSC: 0.6828\n",
            "\n",
            "==============================\n",
            "   FINAL VALIDATION RESULTS   \n",
            "==============================\n",
            "Total Images Processed: 100\n",
            "Average Dice Similarity Coefficient (DSC): 0.6828\n",
            "Average Jaccard Index (IoU): 0.5258\n",
            "==============================\n",
            "\n",
            "\n",
            "Now exporting 10 image sets to:\n",
            "/content/drive/MyDrive/CV_Assessment_01/LaTeX_Report_Images\n",
            "\n",
            "SUCCESS! All 30 report images have been saved to your Google Drive folder.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import drive\n",
        "\n",
        "# --- 1. MOUNT DRIVE ---\n",
        "try:\n",
        "    drive.mount('/content/drive', force_remount=True)\n",
        "    project_path = '/content/drive/MyDrive/CV_Assessment_01'\n",
        "    if os.path.exists(project_path): os.chdir(project_path)\n",
        "    print(f\"Successfully mounted Google Drive and changed directory to {project_path}\")\n",
        "except ValueError as e:\n",
        "    print(f\"Error mounting Google Drive: {e}. Please ensure you authorize the connection promptly.\")\n",
        "    print(\"Cannot proceed without Google Drive. Please re-run the cell and authorize.\")\n",
        "    # Exit or raise to prevent further execution if drive is critical\n",
        "    exit() # Or handle as appropriate\n",
        "\n",
        "# ==========================================\n",
        "# 1. THE ADAPTIVE \"DOUBLE-CLAHE\" PIPELINE\n",
        "# ==========================================\n",
        "def segment_blood_vessels(image_path):\n",
        "    img = cv2.imread(image_path, cv2.IMREAD_COLOR)\n",
        "    if img is None: return None, None\n",
        "\n",
        "    original_shape = img.shape[:2]\n",
        "    img_resized = cv2.resize(img, (800, 800))\n",
        "\n",
        "    b, g, r = cv2.split(img_resized)\n",
        "\n",
        "    _, fov_mask = cv2.threshold(g, 10, 255, cv2.THRESH_BINARY)\n",
        "    kernel_erode = np.ones((15, 15), np.uint8)\n",
        "    fov_mask_eroded = cv2.erode(fov_mask, kernel_erode, iterations=2)\n",
        "\n",
        "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
        "    g_clahe = clahe.apply(g)\n",
        "\n",
        "    background = cv2.medianBlur(g_clahe, 45)\n",
        "    vessels_diff = cv2.subtract(background, g_clahe)\n",
        "\n",
        "    clahe_diff = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8, 8))\n",
        "    vessels_enhanced = clahe_diff.apply(vessels_diff)\n",
        "\n",
        "    valid_pixels = vessels_enhanced[fov_mask_eroded > 0]\n",
        "    if len(valid_pixels) > 0:\n",
        "        mean_val = np.mean(valid_pixels)\n",
        "        std_val = np.std(valid_pixels)\n",
        "        dynamic_thresh = mean_val + (1.2 * std_val)\n",
        "    else:\n",
        "        dynamic_thresh = 20\n",
        "\n",
        "    _, binary_vessels = cv2.threshold(vessels_enhanced, dynamic_thresh, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "    vessels_masked = cv2.bitwise_and(binary_vessels, fov_mask_eroded)\n",
        "\n",
        "    kernel_close = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))\n",
        "    vessels_closed = cv2.morphologyEx(vessels_masked, cv2.MORPH_CLOSE, kernel_close)\n",
        "\n",
        "    num_labels, labels, stats, _ = cv2.connectedComponentsWithStats(vessels_closed, connectivity=8)\n",
        "    final_mask_small = np.zeros_like(vessels_closed)\n",
        "\n",
        "    for i in range(1, num_labels):\n",
        "        if stats[i, cv2.CC_STAT_AREA] > 20:\n",
        "            final_mask_small[labels == i] = 255\n",
        "\n",
        "    final_mask = cv2.resize(final_mask_small, (original_shape[1], original_shape[0]), interpolation=cv2.INTER_NEAREST)\n",
        "\n",
        "    return img, final_mask\n",
        "\n",
        "# ==========================================\n",
        "# 2. VALIDATION METRICS\n",
        "# ==========================================\n",
        "def calculate_metrics(predicted_mask, ground_truth_mask):\n",
        "    S = predicted_mask > 128\n",
        "    G = ground_truth_mask > 128\n",
        "\n",
        "    intersection = np.logical_and(S, G).sum()\n",
        "    union = np.logical_or(S, G).sum()\n",
        "    sum_S = S.sum()\n",
        "    sum_G = G.sum()\n",
        "\n",
        "    dice = (2.0 * intersection) / (sum_S + sum_G) if (sum_S + sum_G) != 0 else 0.0\n",
        "    jaccard = intersection / union if union != 0 else 0.0\n",
        "    return dice, jaccard\n",
        "\n",
        "# ==========================================\n",
        "# 3. BATCH VALIDATION SCRIPT\n",
        "# ==========================================\n",
        "base_path = 'Dataset/IPCV_ ASSIGNMENT_01_DATABASE/Database_For_Practical_Part/For Validation'\n",
        "img_dir = os.path.join(base_path, 'Foundus Images For Validation')\n",
        "gt_dir = os.path.join(base_path, 'Ground Truth For Validation')\n",
        "\n",
        "if not os.path.exists(img_dir) or not os.path.exists(gt_dir):\n",
        "    print(\"Error: Could not find validation folders. Check your paths!\")\n",
        "else:\n",
        "    img_files = sorted([f for f in os.listdir(img_dir) if f.endswith(('.jpg', '.png', '.tif'))])\n",
        "    gt_files = sorted([f for f in os.listdir(gt_dir) if f.endswith(('.jpg', '.png', '.tif'))])\n",
        "\n",
        "    print(f\"Found {len(img_files)} images. Running Advanced Double-CLAHE Pipeline...\\n\")\n",
        "    all_dice_scores = []\n",
        "    all_jaccard_scores = []\n",
        "\n",
        "    for i, (img_name, gt_name) in enumerate(zip(img_files, gt_files)):\n",
        "        img_path = os.path.join(img_dir, img_name)\n",
        "        gt_path = os.path.join(gt_dir, gt_name)\n",
        "\n",
        "        _, pred_mask = segment_blood_vessels(img_path)\n",
        "        gt_mask = cv2.imread(gt_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "        if pred_mask is not None and gt_mask is not None:\n",
        "            if pred_mask.shape != gt_mask.shape:\n",
        "                pred_mask = cv2.resize(pred_mask, (gt_mask.shape[1], gt_mask.shape[0]), interpolation=cv2.INTER_NEAREST)\n",
        "\n",
        "            dice, jaccard = calculate_metrics(pred_mask, gt_mask)\n",
        "            all_dice_scores.append(dice)\n",
        "            all_jaccard_scores.append(jaccard)\n",
        "\n",
        "            if (i + 1) % 10 == 0:\n",
        "                print(f\"Processed {i + 1}/100 images... Current Avg DSC: {np.mean(all_dice_scores):.4f}\")\n",
        "\n",
        "    avg_dice = np.mean(all_dice_scores)\n",
        "    avg_jaccard = np.mean(all_jaccard_scores)\n",
        "\n",
        "    print(\"\\n==============================\")\n",
        "    print(\"   FINAL VALIDATION RESULTS   \")\n",
        "    print(\"==============================\")\n",
        "    print(f\"Total Images Processed: {len(all_dice_scores)}\")\n",
        "    print(f\"Average Dice Similarity Coefficient (DSC): {avg_dice:.4f}\")\n",
        "    print(f\"Average Jaccard Index (IoU): {avg_jaccard:.4f}\")\n",
        "    print(\"==============================\\n\")\n",
        "\n",
        "# ==========================================\n",
        "# 4. EXPORT 10 IMAGES FOR LATEX REPORT\n",
        "# ==========================================\n",
        "    output_folder = '/content/drive/MyDrive/CV_Assessment_01/LaTeX_Report_Images'\n",
        "    os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "    print(f\"\\nNow exporting 10 image sets to:\\n{output_folder}\\n\")\n",
        "\n",
        "    for i in range(10):\n",
        "        img_name = img_files[i]\n",
        "        gt_name = gt_files[i]\n",
        "\n",
        "        img_path = os.path.join(img_dir, img_name)\n",
        "        gt_path = os.path.join(gt_dir, gt_name)\n",
        "\n",
        "        # Run pipeline again just for these 10 to save them\n",
        "        img, pred_mask = segment_blood_vessels(img_path)\n",
        "        gt_mask = cv2.imread(gt_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "        # Define exact filenames for LaTeX\n",
        "        orig_filename = os.path.join(output_folder, f\"img{i+1}_original.png\")\n",
        "        pred_filename = os.path.join(output_folder, f\"img{i+1}_result.png\")\n",
        "        gt_filename = os.path.join(output_folder, f\"img{i+1}_gt.png\")\n",
        "\n",
        "        # Save to Google Drive\n",
        "        cv2.imwrite(orig_filename, img)\n",
        "        cv2.imwrite(pred_filename, pred_mask)\n",
        "        cv2.imwrite(gt_filename, gt_mask)\n",
        "\n",
        "    print(\"SUCCESS! All 30 report images have been saved to your Google Drive folder.\")"
      ]
    }
  ]
}